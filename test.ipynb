{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4e68c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tools.accommodations.apis import Accommodations\n",
    "from mcts.travel.semantic.query_parsing import call_local_llm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e0037a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "base_url = \"http://localhost:11434\"  \n",
    "model = \"deepseek-r1:14b\"\n",
    "\n",
    "# --------- Example inputs (replace with your real parsed/state/slot if needed) ----------\n",
    "parsed = {\n",
    "  \"org\": \"Fort Lauderdale\",\n",
    "  \"dest\": \"Louisiana\",\n",
    "  \"days\": 7,\n",
    "  \"date\": [\"2022-03-08\",\"2022-03-09\",\"2022-03-10\",\"2022-03-11\",\"2022-03-12\",\"2022-03-13\",\"2022-03-14\"],\n",
    "  \"people_number\": 2,\n",
    "  \"budget\": 4400,\n",
    "  \"local_constraint\": {\n",
    "    \"cuisine\": [\"Cajun\", \"Seafood\"],\n",
    "    \"avoid\": [],\n",
    "    \"room_type\": \"entire room\",\n",
    "    \"children_under_10\": True\n",
    "  }\n",
    "}\n",
    "\n",
    "# Keep state minimal but sufficient for retrieval\n",
    "state = {\n",
    "  \"current_city\": \"New Orleans\",\n",
    "  \"day_idx\": 2,\n",
    "  \"used_restaurant_ids\": [101, 109, 155],\n",
    "  \"budget\": {\"total\": 4400, \"spent\": 1200, \"remaining\": 3200}\n",
    "}\n",
    "\n",
    "slot = {\n",
    "  \"type\": \"meal\",\n",
    "  \"meal_type\": \"dinner\",\n",
    "  \"city\": \"New Orleans\",\n",
    "  \"top_k\": 5\n",
    "}\n",
    "\n",
    "# --------- Build the prompt ----------\n",
    "prompt = f\"\"\"\n",
    "You are a senior Python engineer. Generate executable Python code ONLY.\n",
    "\n",
    "Task:\n",
    "Implement a function:\n",
    "\n",
    "    def retrieve_candidates(parsed: dict, state: dict, slot: dict, tables: dict) -> list[dict]:\n",
    "\n",
    "It must retrieve restaurant candidates for a MEAL slot from tables[\"restaurants\"] (a pandas DataFrame).\n",
    "\n",
    "Constraints & Requirements:\n",
    "1) Do NOT import any new libraries. Assume pandas is already imported as pd by the caller.\n",
    "2) Do NOT read/write files, do NOT use network, do NOT use eval/exec.\n",
    "3) The function must be deterministic and runnable as-is.\n",
    "4) The function must:\n",
    "   - Filter rows by City == slot[\"city\"]\n",
    "   - Filter rows by MealType == slot[\"meal_type\"]\n",
    "   - Prefer cuisines in parsed[\"local_constraint\"][\"cuisine\"] if present (soft preference, not hard filter unless it helps ensure enough candidates)\n",
    "   - Apply dedup: exclude rows whose id is in state[\"used_restaurant_ids\"]\n",
    "   - Apply a budget-aware soft filter:\n",
    "       * compute per_meal_cap = max(10, (state[\"budget\"][\"remaining\"] / remaining_meals_estimate))\n",
    "       * remaining_meals_estimate = max(1, (parsed[\"days\"] - state[\"day_idx\"]) * 2)   # assume 2 meals/day remaining\n",
    "       * keep rows with \"Average Cost\" <= per_meal_cap if that yields at least 10 rows; otherwise relax the cap and keep top by score.\n",
    "   - Score candidates with a clear scoring function that uses:\n",
    "       * cuisine match bonus (if cuisine in preferred list)\n",
    "       * higher Rating better\n",
    "       * lower Average Cost better\n",
    "     Then sort by score desc, Rating desc, Average Cost asc.\n",
    "   - Return a list of dicts with keys:\n",
    "       [\"id\",\"Name\",\"City\",\"Cuisine\",\"Average Cost\",\"MealType\",\"Rating\",\"PriceLevel\",\"score\",\"per_meal_cap\",\"cap_relaxed\"]\n",
    "\n",
    "5) Fallback behavior:\n",
    "   - If after filtering and dedup you have < 10 candidates, you must relax in this order:\n",
    "       (a) ignore MealType constraint\n",
    "       (b) ignore cuisine preference (still score it if present)\n",
    "       (c) allow higher cost (ignore cap)\n",
    "   - Always return up to slot[\"top_k\"] candidates if possible.\n",
    "   - If DataFrame is empty or no candidates exist, return an empty list (no exception).\n",
    "\n",
    "Given Inputs:\n",
    "KB schema:\n",
    "tables[\"restaurants\"] columns:\n",
    "- id (int), Name (str), City (str), Cuisine (str), Average Cost (float), MealType (str), Rating (float), PriceLevel (int)\n",
    "\n",
    "parsed = {json.dumps(parsed, ensure_ascii=False)}\n",
    "state = {json.dumps(state, ensure_ascii=False)}\n",
    "slot = {json.dumps(slot, ensure_ascii=False)}\n",
    "\n",
    "Output format:\n",
    "- Output ONLY valid Python code.\n",
    "- Do not include markdown fences.\n",
    "- Code must define retrieve_candidates exactly with that signature.\n",
    "- You may define small helper functions inside retrieve_candidates.\n",
    "- Do not output any explanations, comments are allowed but keep them minimal.\n",
    "\n",
    "Now generate the code.\n",
    "\"\"\".strip()\n",
    "\n",
    "# --------- Call your local LLM ----------\n",
    "code = call_local_llm(base_url, model, prompt, timeout=666.0)\n",
    "\n",
    "print(code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1130f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== LLM: produce QuerySpec ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 294\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(candidates2, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 248\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== LLM: produce QuerySpec ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 248\u001b[0m     llm_text \u001b[38;5;241m=\u001b[39m \u001b[43mcall_chat_completions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[warn] /v1/chat/completions failed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTrying /api/generate fallback...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 157\u001b[0m, in \u001b[0;36mcall_chat_completions\u001b[0;34m(cfg, messages, temperature)\u001b[0m\n\u001b[1;32m    155\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m payload \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: cfg\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: messages, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature}\n\u001b[0;32m--> 157\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m r\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m    159\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/requests/adapters.py:644\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    641\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 644\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    647\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    784\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    803\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/urllib3/connectionpool.py:534\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 534\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/site-packages/urllib3/connection.py:565\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    562\u001b[0m _shutdown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshutdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 565\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/http/client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1377\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1378\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1379\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/http/client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/http/client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 281\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/fmtravelplanner/lib/python3.9/socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 1) Example inputs\n",
    "# -----------------------\n",
    "parsed = {\n",
    "    \"org\": \"Fort Lauderdale\",\n",
    "    \"dest\": \"Louisiana\",\n",
    "    \"days\": 7,\n",
    "    \"date\": [\n",
    "        \"2022-03-08\",\n",
    "        \"2022-03-09\",\n",
    "        \"2022-03-10\",\n",
    "        \"2022-03-11\",\n",
    "        \"2022-03-12\",\n",
    "        \"2022-03-13\",\n",
    "        \"2022-03-14\",\n",
    "    ],\n",
    "    \"people_number\": 2,\n",
    "    \"budget\": 4400,\n",
    "    \"local_constraint\": {\"cuisine\": [\"Cajun\", \"Seafood\"], \"avoid\": [], \"room_type\": \"entire room\", \"children_under_10\": True},\n",
    "}\n",
    "\n",
    "state = {\n",
    "    \"current_city\": \"New Orleans\",\n",
    "    \"day_idx\": 2,\n",
    "    \"used_restaurant_ids\": [101, 109, 155],\n",
    "    \"budget\": {\"total\": 4400, \"spent\": 1200, \"remaining\": 3200},\n",
    "}\n",
    "\n",
    "slot = {\"type\": \"meal\", \"meal_type\": \"dinner\", \"city\": \"New Orleans\", \"top_k\": 30}\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 2) Fake Restaurants DB (replace with your real CSV/DB)\n",
    "# -----------------------\n",
    "def build_fake_restaurants_df() -> pd.DataFrame:\n",
    "    # A tiny dataset that is sufficient for testing logic.\n",
    "    rows = [\n",
    "        {\"id\": 101, \"Name\": \"Bayou Bites\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Cajun\", \"Average Cost\": 60, \"Rating\": 4.6},\n",
    "        {\"id\": 109, \"Name\": \"Seafood Central\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Seafood\", \"Average Cost\": 85, \"Rating\": 4.5},\n",
    "        {\"id\": 155, \"Name\": \"Cajun Corner\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Cajun\", \"Average Cost\": 70, \"Rating\": 4.4},\n",
    "        {\"id\": 201, \"Name\": \"Gumbo House\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Cajun\", \"Average Cost\": 75, \"Rating\": 4.7},\n",
    "        {\"id\": 202, \"Name\": \"Oyster & Co\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Seafood\", \"Average Cost\": 95, \"Rating\": 4.8},\n",
    "        {\"id\": 203, \"Name\": \"Fusion Wharf\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Seafood;Cajun\", \"Average Cost\": 110, \"Rating\": 4.3},\n",
    "        {\"id\": 204, \"Name\": \"Budget Po-Boys\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Seafood\", \"Average Cost\": 35, \"Rating\": 4.1},\n",
    "        {\"id\": 205, \"Name\": \"Late Night NOLA\", \"City\": \"New Orleans\", \"Meal Type\": \"dinner\", \"Cuisine\": \"American\", \"Average Cost\": 40, \"Rating\": 4.2},\n",
    "        {\"id\": 301, \"Name\": \"Baton Rouge Cajun\", \"City\": \"Baton Rouge\", \"Meal Type\": \"dinner\", \"Cuisine\": \"Cajun\", \"Average Cost\": 55, \"Rating\": 4.4},\n",
    "    ]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 3) Deterministic retrieval tool\n",
    "# -----------------------\n",
    "def search_restaurants(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    city: str,\n",
    "    meal_type: str,\n",
    "    cuisine_any: Optional[List[str]] = None,\n",
    "    exclude_ids: Optional[List[int]] = None,\n",
    "    max_avg_cost_per_person: Optional[float] = None,\n",
    "    top_k: int = 30,\n",
    "    sort: str = \"rating_desc_cost_asc\",\n",
    ") -> Tuple[List[Dict[str, Any]], Dict[str, Any]]:\n",
    "    \"\"\"Deterministic tool: filters + sorting + top_k. Returns candidates + meta.\"\"\"\n",
    "    meta: Dict[str, Any] = {\"filters\": {}, \"counts\": {}}\n",
    "    work = df.copy()\n",
    "\n",
    "    meta[\"counts\"][\"start\"] = len(work)\n",
    "\n",
    "    # hard filters\n",
    "    work = work[work[\"City\"].astype(str).str.lower() == city.lower()]\n",
    "    meta[\"counts\"][\"after_city\"] = len(work)\n",
    "\n",
    "    work = work[work[\"Meal Type\"].astype(str).str.lower() == meal_type.lower()]\n",
    "    meta[\"counts\"][\"after_meal_type\"] = len(work)\n",
    "\n",
    "    if exclude_ids:\n",
    "        work = work[~work[\"id\"].isin(exclude_ids)]\n",
    "    meta[\"counts\"][\"after_exclude\"] = len(work)\n",
    "\n",
    "    # soft filters\n",
    "    if cuisine_any:\n",
    "        pat = \"|\".join(re.escape(x.lower()) for x in cuisine_any)\n",
    "        work = work[work[\"Cuisine\"].astype(str).str.lower().str.contains(pat, na=False)]\n",
    "    meta[\"counts\"][\"after_cuisine_any\"] = len(work)\n",
    "\n",
    "    if max_avg_cost_per_person is not None:\n",
    "        work = work[pd.to_numeric(work[\"Average Cost\"], errors=\"coerce\") <= float(max_avg_cost_per_person)]\n",
    "    meta[\"counts\"][\"after_cost_cap\"] = len(work)\n",
    "\n",
    "    # sorting\n",
    "    if sort == \"rating_desc_cost_asc\":\n",
    "        work[\"_rating\"] = pd.to_numeric(work[\"Rating\"], errors=\"coerce\")\n",
    "        work[\"_cost\"] = pd.to_numeric(work[\"Average Cost\"], errors=\"coerce\")\n",
    "        work = work.sort_values(by=[\"_rating\", \"_cost\"], ascending=[False, True])\n",
    "    elif sort == \"cost_asc_rating_desc\":\n",
    "        work[\"_rating\"] = pd.to_numeric(work[\"Rating\"], errors=\"coerce\")\n",
    "        work[\"_cost\"] = pd.to_numeric(work[\"Average Cost\"], errors=\"coerce\")\n",
    "        work = work.sort_values(by=[\"_cost\", \"_rating\"], ascending=[True, False])\n",
    "\n",
    "    # top-k\n",
    "    work = work.head(int(top_k))\n",
    "\n",
    "    candidates: List[Dict[str, Any]] = []\n",
    "    for _, r in work.iterrows():\n",
    "        candidates.append(\n",
    "            {\n",
    "                \"id\": int(r[\"id\"]),\n",
    "                \"name\": str(r[\"Name\"]),\n",
    "                \"city\": str(r[\"City\"]),\n",
    "                \"meal_type\": str(r[\"Meal Type\"]),\n",
    "                \"cuisine\": str(r[\"Cuisine\"]),\n",
    "                \"avg_cost\": float(r[\"Average Cost\"]),\n",
    "                \"rating\": float(r[\"Rating\"]),\n",
    "            }\n",
    "        )\n",
    "\n",
    "    meta[\"counts\"][\"returned\"] = len(candidates)\n",
    "    meta[\"applied\"] = {\n",
    "        \"city\": city,\n",
    "        \"meal_type\": meal_type,\n",
    "        \"cuisine_any\": cuisine_any,\n",
    "        \"exclude_ids\": exclude_ids,\n",
    "        \"max_avg_cost_per_person\": max_avg_cost_per_person,\n",
    "        \"top_k\": top_k,\n",
    "        \"sort\": sort,\n",
    "    }\n",
    "    return candidates, meta\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4) LLM calling helpers (Ollama-compatible)\n",
    "# -----------------------\n",
    "@dataclass\n",
    "class LLMConfig:\n",
    "    base_url: str = \"http://127.0.0.1:11434\"\n",
    "    model: str = \"deepseek\"  # change to your model\n",
    "    timeout: float = 120.0\n",
    "\n",
    "\n",
    "def call_chat_completions(cfg: LLMConfig, messages: List[Dict[str, str]], temperature: float = 0.0) -> str:\n",
    "    \"\"\"Calls /v1/chat/completions (Ollama).\"\"\"\n",
    "    url = f\"{cfg.base_url.rstrip('/')}/v1/chat/completions\"\n",
    "    payload = {\"model\": cfg.model, \"messages\": messages, \"temperature\": temperature}\n",
    "    r = requests.post(url, json=payload, timeout=cfg.timeout)\n",
    "    r.raise_for_status()\n",
    "    data = r.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def call_generate(cfg: LLMConfig, prompt: str) -> str:\n",
    "    \"\"\"Fallback: calls /api/generate (Ollama classic).\"\"\"\n",
    "    url = f\"{cfg.base_url.rstrip('/')}/api/generate\"\n",
    "    payload = {\"model\": cfg.model, \"prompt\": prompt, \"stream\": False}\n",
    "    r = requests.post(url, json=payload, timeout=cfg.timeout)\n",
    "    r.raise_for_status()\n",
    "    return r.json().get(\"response\", \"\")\n",
    "\n",
    "\n",
    "def extract_json_object(text: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Robust-ish JSON extractor: finds first {...} block and parses it.\n",
    "    Works for models that sometimes wrap JSON in text.\n",
    "    \"\"\"\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.S)\n",
    "    if not m:\n",
    "        raise ValueError(\"No JSON object found in LLM output.\")\n",
    "    return json.loads(m.group(0))\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 5) Prompt: Ask LLM to produce QuerySpec only\n",
    "# -----------------------\n",
    "def build_queryspec_prompt(parsed: dict, state: dict, slot: dict) -> List[Dict[str, str]]:\n",
    "    schema = {\n",
    "        \"tool\": \"search_restaurants\",\n",
    "        \"arguments\": {\n",
    "            \"city\": \"string (required)\",\n",
    "            \"meal_type\": \"string (required)\",\n",
    "            \"cuisine_any\": \"list[string] | null\",\n",
    "            \"exclude_ids\": \"list[int] | null\",\n",
    "            \"max_avg_cost_per_person\": \"number | null\",\n",
    "            \"top_k\": \"int\",\n",
    "            \"sort\": \"rating_desc_cost_asc | cost_asc_rating_desc\",\n",
    "        },\n",
    "        \"fallbacks\": [\n",
    "            {\"when\": \"no_results\", \"action\": \"relax_cost_cap\", \"scale\": 1.25},\n",
    "            {\"when\": \"still_no_results\", \"action\": \"drop_cuisine_filter\"},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    system = (\n",
    "        \"You are a query-planning controller for a deterministic database tool. \"\n",
    "        \"You MUST output ONLY a single JSON object and nothing else. \"\n",
    "        \"Do NOT invent any restaurants. \"\n",
    "        \"Your task: produce a tool call spec that can be executed as-is.\"\n",
    "    )\n",
    "\n",
    "    user = {\n",
    "        \"task\": \"Generate a QuerySpec JSON to retrieve candidate restaurants for the current planning slot.\",\n",
    "        \"parsed\": parsed,\n",
    "        \"state\": state,\n",
    "        \"slot\": slot,\n",
    "        \"available_tool_schema\": schema,\n",
    "        \"notes\": [\n",
    "            \"Hard constraints: city, meal_type, exclude_ids must be applied.\",\n",
    "            \"Soft constraints: cuisine_any is preferred if it doesn't eliminate all options.\",\n",
    "            \"Budget: infer max_avg_cost_per_person from remaining budget in state; be conservative.\",\n",
    "            \"Return top_k candidates as requested by slot.\",\n",
    "            \"Sort by rating desc then cost asc, unless you explain otherwise in JSON fields (but still JSON-only).\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(user, ensure_ascii=False)},\n",
    "    ]\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 6) End-to-end test\n",
    "# -----------------------\n",
    "def main() -> None:\n",
    "    cfg = LLMConfig(\n",
    "        base_url=\"http://127.0.0.1:11434\",\n",
    "        model=\"deepseek-r1:14b\",  # change to your local model name, e.g. \"deepseek-r1:14b\"\n",
    "        timeout=666.0,\n",
    "    )\n",
    "\n",
    "    df = build_fake_restaurants_df()\n",
    "\n",
    "    # Round 1: Ask LLM for QuerySpec\n",
    "    messages = build_queryspec_prompt(parsed, state, slot)\n",
    "    print(\"\\n=== LLM: produce QuerySpec ===\")\n",
    "    try:\n",
    "        llm_text = call_chat_completions(cfg, messages, temperature=0.0)\n",
    "    except Exception as e:\n",
    "        print(f\"[warn] /v1/chat/completions failed: {e}\\nTrying /api/generate fallback...\\n\")\n",
    "        llm_text = call_generate(cfg, prompt=messages[0][\"content\"] + \"\\n\" + messages[1][\"content\"])\n",
    "\n",
    "    print(llm_text)\n",
    "\n",
    "    queryspec = extract_json_object(llm_text)\n",
    "    assert queryspec.get(\"tool\") == \"search_restaurants\", f\"Unexpected tool: {queryspec.get('tool')}\"\n",
    "    args = queryspec.get(\"arguments\") or {}\n",
    "\n",
    "    # Execute deterministic tool\n",
    "    candidates, meta = search_restaurants(df, **args)\n",
    "    print(\"\\n=== Tool execution meta ===\")\n",
    "    print(json.dumps(meta, indent=2, ensure_ascii=False))\n",
    "    print(\"\\n=== Candidates returned ===\")\n",
    "    print(json.dumps(candidates, indent=2, ensure_ascii=False))\n",
    "\n",
    "    # Round 2 (optional): If empty, ask LLM to adapt based on meta\n",
    "    if not candidates:\n",
    "        print(\"\\n=== No candidates. Ask LLM to adapt QuerySpec based on meta ===\")\n",
    "        adapt_messages = [\n",
    "            {\"role\": \"system\", \"content\": \"You must output ONLY one JSON object (QuerySpec). No extra text.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": json.dumps(\n",
    "                    {\n",
    "                        \"previous_queryspec\": queryspec,\n",
    "                        \"tool_meta\": meta,\n",
    "                        \"instruction\": \"Revise the QuerySpec using fallbacks (e.g., relax cost cap or drop cuisine filter) to obtain non-empty results while keeping hard constraints.\",\n",
    "                    },\n",
    "                    ensure_ascii=False,\n",
    "                ),\n",
    "            },\n",
    "        ]\n",
    "        llm_text2 = call_chat_completions(cfg, adapt_messages, temperature=0.0)\n",
    "        print(llm_text2)\n",
    "        queryspec2 = extract_json_object(llm_text2)\n",
    "        candidates2, meta2 = search_restaurants(df, **(queryspec2.get(\"arguments\") or {}))\n",
    "        print(\"\\n=== Tool execution meta (round2) ===\")\n",
    "        print(json.dumps(meta2, indent=2, ensure_ascii=False))\n",
    "        print(\"\\n=== Candidates returned (round2) ===\")\n",
    "        print(json.dumps(candidates2, indent=2, ensure_ascii=False))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmtravelplanner",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
